import itertools
import operator
import os

import natsort
import pyo64 as pyo

from mu.utils import interpolations
from mu.utils import tools

from mutools import activity_levels


"""Module for Speech processing / SpeechEngine.

Unlike other engines, the SpeechEngine barely depends on data from other
voices (it is rather independent from surrounding sounds). Because of this
special feature, the Engines that will be used in the Segment object will
become initalised outside of the respective Segment object.

Different engines include:

    (1) BrokenRadio aka the time machine

        Class to process samples that has been cut in small slices. It's possible
        to mix multiple sources and to process each short sound file individually.
        Furthermore background noise can be added.

    (2) SimplePlayer & Looper

        Class to process one long sample.
"""


class SlicePlayer(pyo.EventInstrument):
    fadein = 0.02
    fadeout = 0.03

    def __init__(self, **args) -> None:
        pyo.EventInstrument.__init__(self, **args)

        attributes_to_set_zero = (
            "original_lv",
            "harmonizer_lv",
            "ringmodulation_lv",
            "filter_lv",
            "distortion_lv",
            "noise_lv",
            "lorenz_lv",
            "disturbance_lv",
        )
        attributes_to_set_n = (
            ("lv", 1),
            ("rm_freq", 200),
            ("filter_freq", 200),
            ("filter_q", 1),
            ("h_transpo", -2),
            ("lorenz_pitch", 0.4),
            ("lorenz_chaos", 0.5),
            ("chenlee_pitch", 0.75),
            ("chenlee_chaos", 0.5),
        )
        attributes_to_set_n += tuple((attr, 0) for attr in attributes_to_set_zero)
        for attribute, value in attributes_to_set_n:
            try:
                getattr(self, attribute)
            except AttributeError:
                setattr(self, attribute, value)

        fade = pyo.Fader(fadein=self.fadein, fadeout=self.fadeout).play(dur=self.dur)
        fade *= self.lv

        if self.path is not None:
            self.osc = SlicePlayer.make_osc(self.path, mul=fade).play(dur=self.dur)
            self.original = SlicePlayer.make_osc(
                self.path, mul=fade * self.original_lv
            ).out(1, dur=self.dur)
            self.h = pyo.Harmonizer(
                self.osc, transpo=self.h_transpo, mul=self.harmonizer_lv
            ).out(1)
            self.filtered = pyo.Reson(
                self.osc, freq=self.filter_freq, q=self.filter_q, mul=self.filter_lv
            ).out(1)
            self.distr = pyo.Disto(self.osc, mul=self.distortion_lv).out(1)
            self.rm = (pyo.Sine(self.rm_freq) * self.osc * self.ringmodulation_lv).out(
                1
            )

        # ambient noise
        noise_dur = self.dur + self.fadein + self.fadeout
        self.noise_fader = pyo.Linseg(
            [(0, self.ambient_noise_lv[0]), (self.dur, self.ambient_noise_lv[1])]
        ).play(dur=noise_dur)

        self.lorenz = pyo.Lorenz(
            pitch=self.lorenz_pitch, chaos=self.lorenz_chaos, mul=self.lorenz_lv
        ).play(dur=noise_dur)

        self.brown = pyo.BrownNoise(mul=self.noise_lv).play(dur=noise_dur)

        self.ambient_noise = ((self.brown + self.lorenz) * self.noise_fader * fade).out(
            1
        )

        # additional noise similar to sounds generated by natural radio, I love it!
        self.disturbance = pyo.ChenLee(
            pitch=self.chenlee_pitch,
            chaos=self.chenlee_chaos,
            mul=fade * self.chenlee_lv,
        ).out(1)

    @staticmethod
    def make_osc(path: str, mul=1) -> pyo.Osc:
        soundfile = pyo.SndTable(path)
        return pyo.Osc(soundfile, freq=soundfile.getRate(), interp=4, mul=mul)


class BrokenRadio(object):
    # aka the time machine

    # each effect has an activity_lv (0 -> never played, 10 -> always played)
    # and a (dynamic) level (has to be an object that understands 'next')
    __effects = (
        "original",
        "transposition",
        "harmonizer",
        "filter",
        "distortion",
        "ringmodulation",
        "noise",
        "lorenz",
        "chenlee",
    )

    def __init__(
        self,
        sources: tuple,
        source_decider: tuple = None,
        activity_lv_per_effect: dict = {},
        level_per_effect: dict = {},
        volume: float = 1,
        curve: interpolations.InterpolationLine = interpolations.InterpolationLine(
            [
                interpolations.FloatInterpolationEvent(0.1, 0),
                interpolations.FloatInterpolationEvent(0.8, 1),
                interpolations.FloatInterpolationEvent(0.1, 1),
                interpolations.FloatInterpolationEvent(0, 0),
            ]
        ),
        duration: float = 10,
    ) -> None:

        # TODO(add the possibility to skip samples in sources)
        # TODO(add the possibility to chose how to interlock sources, either
        # with going through all samples or through indexing them)
        # TODO(add the possibility to shuffle samples and not using the
        # original order)

        if source_decider is None:
            source_decider = itertools.cycle(range(len(sources)))

        self.sources = sources
        self.volume = volume
        self.curve = curve
        self.duration = duration
        self.source_decider = source_decider

        for effect in self.__effects:
            if effect not in activity_lv_per_effect:
                activity_lv_per_effect.update({effect: 0})

            if effect not in level_per_effect:
                level_per_effect.update({effect: itertools.cycle((1,))})

        self.level_per_effect = level_per_effect
        self.activity_lv_per_effect = activity_lv_per_effect

        # sr and nchnls is hard coded
        self.server = pyo.Server(sr=96000, audio="offline", nchnls=1).boot()
        self.path_per_source = BrokenRadio.detect_files(self.sources)
        self.data_per_source = BrokenRadio.detect_data_per_source(self.path_per_source)
        self.activity_object_per_effect = {
            effect: activity_levels.ActivityLevel() for effect in self.__effects
        }

        self.maxima_n_events = max(len(paths) for paths in self.path_per_source)

        self.sample_key_per_event = tuple(
            (next(self.source_decider), idx) for idx in range(self.maxima_n_events)
        )

        self.sample_path_per_event = tuple(
            self.path_per_source[key[0]][key[1]] for key in self.sample_key_per_event
        )

        ig1 = operator.itemgetter(1)
        self.duration_per_sample = tuple(
            ig1(self.data_per_source[key[0]][key[1]])
            for key in self.sample_key_per_event
        )

        # TODO(ADD POTENTIAL PAUSE [not all slices have to appear immediately
        # after each other!!!!])
        self.duration_per_event = tuple(dps - 1 for dps in self.duration_per_sample)

    @staticmethod
    def detect_files(sources: tuple) -> tuple:
        files_per_source = []
        for path in sources:
            all_files = natsort.natsorted(os.listdir(path))
            soundfiles = filter(lambda f: f.endswith("wav"), all_files)
            files_per_source.append(tuple(path + f for f in soundfiles))
        return tuple(files_per_source)

    @staticmethod
    def detect_data_per_source(path_per_source: tuple) -> tuple:
        return tuple(
            tuple(pyo.sndinfo(path) for path in source) for source in path_per_source
        )

    @staticmethod
    def convert_sample_names2pyo_objects(path: str, files: tuple) -> tuple:
        return tuple(pyo.SndTable(path + f) for f in files)

    def __call__(self, name: str) -> None:
        self.server.recordOptions(dur=self.duration, filename=name, sampletype=4)

        import random

        random.seed(1)

        n_events = tools.find_closest_index(
            self.duration, tools.accumulate_from_zero(self.duration_per_event)
        )

        duration_per_event = self.duration_per_event[:n_events]
        sample_path_per_event = self.sample_path_per_event[:n_events]

        lv_per_effect = {
            "{}_lv".format(effect): tuple(
                next(self.level_per_effect[effect])
                if self.activity_object_per_effect[effect](
                    self.activity_lv_per_effect[effect]
                )
                else 0
                for i in duration_per_event
            )
            for effect in self.__effects
        }

        ambient_noise_lv_per_event = tuple(
            random.uniform(0.2, 0.4) for i in duration_per_event
        )
        ambient_noise_lv_per_event = tuple(
            (a, b)
            for a, b in zip(
                (0,) + ambient_noise_lv_per_event, ambient_noise_lv_per_event
            )
        )

        # general dynamic level for each slice
        event_lv = tuple(self.volume * lv for lv in self.curve(n_events, "points"))

        filter_freq_per_event = tuple(
            random.uniform(150.0, 250.0) for i in duration_per_event
        )
        filter_q_per_event = tuple(random.uniform(1.0, 2.0) for i in duration_per_event)

        rm_freq_per_event = tuple(
            random.uniform(1500.0, 2000.0) for i in duration_per_event
        )

        transpo_per_event = tuple(random.uniform(-7, 7) for i in duration_per_event)

        chenlee_chaos_per_event = tuple(
            random.uniform(0.5, 1) for i in duration_per_event
        )
        chenlee_pitch_per_event = tuple(
            random.uniform(0.5, 0.75) for i in duration_per_event
        )

        lorenz_chaos_per_event = tuple(
            random.uniform(0.5, 0.7) for i in duration_per_event
        )
        lorenz_pitch_per_event = tuple(
            random.uniform(0.5, 0.6) for i in duration_per_event
        )

        e = pyo.Events(
            instr=SlicePlayer,
            path=sample_path_per_event,
            dur=duration_per_event,
            lv=event_lv,
            filter_freq=filter_freq_per_event,
            filter_q=filter_q_per_event,
            rm_freq=rm_freq_per_event,
            h_transpo=transpo_per_event,
            chenlee_chaos=chenlee_chaos_per_event,
            chenlee_pitch=chenlee_pitch_per_event,
            lorenz_chaos=lorenz_chaos_per_event,
            lorenz_pitch=lorenz_pitch_per_event,
            ambient_noise_lv=ambient_noise_lv_per_event,
            **lv_per_effect,
        )
        e.play()

        self.server.start()
